import json
import os
import unicodedata
import pandas as pd


# =========================
#  HÃ€M CHUáº¨N HOÃ TEXT
# =========================
def normalize(text: str) -> str:
    if not isinstance(text, str):
        return ""
    text = text.lower()
    return unicodedata.normalize("NFD", text).encode("ascii", "ignore").decode("utf-8")


# =========================
#  Äá»ŒC Äáº¶C Táº¢ CSDL
# =========================
def load_specification(excel_file: str):
    df = pd.read_excel(excel_file)

    entries = []         # Danh sÃ¡ch giÃ¡ trá»‹ phÃ¢n loáº¡i
    group_fields = {}    # Danh sÃ¡ch field theo tá»«ng nhÃ³m

    current_group = None
    current_field = None

    for _, row in df.iterrows():
        group_cell = row.get("Unnamed: 1", None)
        field_cell = row.get("Unnamed: 3", None)
        code = row.get("Unnamed: 6", None)
        label = row.get("Unnamed: 7", None)

        # NhÃ³m lá»›p Ä‘á»‘i tÆ°á»£ng
        if isinstance(group_cell, str):
            current_group = group_cell.strip()
            if current_group not in group_fields:
                group_fields[current_group] = []

        # Field trong nhÃ³m
        if isinstance(field_cell, str):
            current_field = field_cell.strip()
            if current_field not in group_fields[current_group]:
                group_fields[current_group].append(current_field)

        # Náº¿u cÃ³ mÃ£ + nhÃ£n â†’ Ä‘Ã¢y lÃ  1 entry phÃ¢n loáº¡i
        if current_group and current_field and pd.notna(code) and pd.notna(label):
            entries.append({
                "group": current_group,
                "field": current_field,
                "code": str(code).strip(),
                "label": str(label).strip(),
                "norm_label": normalize(str(label)),
                "order": len(entries)
            })

    # Sort theo Ä‘á»™ dÃ i tá»« khoÃ¡ Ä‘á»ƒ match chÃ­nh xÃ¡c
    entries_sorted = sorted(entries, key=lambda e: -len(e["norm_label"]))

    return entries_sorted, group_fields


# =========================
#  MATCH KEYWORD
# =========================
def classify_point(name: str, spec_entries):
    norm_name = normalize(name)

    for entry in spec_entries:
        if entry["norm_label"] and entry["norm_label"] in norm_name:
            return entry

    return None


# =========================
#  XOÃ TRÃ™NG NAME
# =========================
def remove_duplicate_points(features):
    seen = set()
    result = []

    for f in features:
        name = f.get("properties", {}).get("name", "")
        key = normalize(name)

        if key:
            if key in seen:
                continue
            seen.add(key)

        result.append(f)

    return result


# =========================
#  MAIN PROCESS
# =========================
def main():
    print("=== PHÃ‚N LOáº I GEOJSON THEO Äáº¶C Táº¢ + TÃCH FILE + THá»NG KÃŠ ===\n")

    # INPUT GEOJSON
    geo_dir = input("Nháº­p Ä‘Æ°á»ng dáº«n chá»©a file GEOJSON: ").strip()
    geo_name = input("Nháº­p tÃªn file GEOJSON: ").strip()
    geo_path = os.path.join(geo_dir, geo_name)

    # INPUT Äáº¶C Táº¢
    spec_dir = input("\nNháº­p Ä‘Æ°á»ng dáº«n chá»©a file Äáº·c táº£ CSDL: ").strip()
    spec_name = input("Nháº­p tÃªn file Äáº·c táº£ CSDL: ").strip()
    spec_path = os.path.join(spec_dir, spec_name)

    # OUTPUT DIR
    out_dir = input("\nNháº­p Ä‘Æ°á»ng dáº«n thÆ° má»¥c Ä‘áº§u ra: ").strip()
    if not os.path.exists(out_dir):
        os.makedirs(out_dir)

    # LOAD DATA
    print("\nğŸ“¥ Äang Ä‘á»c dá»¯ liá»‡u ...")
    with open(geo_path, "r", encoding="utf-8") as f:
        geo = json.load(f)

    spec_entries, group_fields = load_specification(spec_path)

    print(f"â¡ Sá»‘ dÃ²ng phÃ¢n loáº¡i Ä‘á»c Ä‘Æ°á»£c: {len(spec_entries)}")
    print(f"â¡ Sá»‘ nhÃ³m lá»›p Ä‘á»‘i tÆ°á»£ng: {len(group_fields)}")

    # REMOVE DUPLICATE
    print("\nğŸ§¹ Äang loáº¡i point trÃ¹ng ...")
    features = remove_duplicate_points(geo["features"])

    print(f"â¡ Sá»‘ point sau khi loáº¡i trÃ¹ng: {len(features)}")

    # CLASSIFY
    print("\nğŸ· Äang phÃ¢n loáº¡i point ...")
    classified = []

    for f in features:
        props = f.setdefault("properties", {})
        name_goc = props.get("name", "").strip()

        entry = classify_point(name_goc, spec_entries)
        if entry is None:
            continue

        group = entry["group"]
        field = entry["field"]

        # ThÃªm nhÃ³m lá»›p
        props["nhomLop"] = group

        # ThÃªm cÃ¡c field thuá»™c nhÃ³m (khÃ´ng match â†’ null)
        for fld in group_fields[group]:
            props[fld] = None

        # Field match tá»« keyword
        props[field] = entry["code"]

        # ThÃªm loaiDoiTuong
        props["loaiDoiTuong"] = entry["label"]

        # ThÃªm cá»™t `ten`
        label = entry["label"]
        props["ten"] = f"{label} {name_goc}".strip()

        # Order Ä‘á»ƒ sort
        props["_order"] = entry["order"]

        classified.append(f)

    print(f"â¡ Tá»•ng sá»‘ point Ä‘Æ°á»£c phÃ¢n loáº¡i: {len(classified)}")

    # SORT
    classified_sorted = sorted(
        classified,
        key=lambda f: (
            f["properties"].get("_order", 999999),
            f["properties"].get("name", "")
        )
    )

    # TÃCH FILE THEO NHÃ“M
    print("\nğŸ“¤ Äang tÃ¡ch file theo tá»«ng nhÃ³m lá»›p ...")

    group_map = {}
    for f in classified_sorted:
        group = f["properties"]["nhomLop"]
        group_map.setdefault(group, []).append(f)

    for group, feats in group_map.items():
        out_geo = {"type": "FeatureCollection", "features": feats}
        out_path = os.path.join(out_dir, f"{group}.geojson")

        with open(out_path, "w", encoding="utf-8") as fo:
            json.dump(out_geo, fo, ensure_ascii=False, indent=4)

        print(f"   âœ” {group}: {len(feats)} point")

    # FILE THá»NG KÃŠ
    print("\nğŸ“Š Äang táº¡o file thá»‘ng kÃª ...")

    stats = []
    for f in classified_sorted:
        p = f["properties"]
        stats.append({
            "nhomLop": p["nhomLop"],
            "maDoiTuong": p.get("maDoiTuong", None),
            "loaiDoiTuong": p.get("loaiDoiTuong", None)
        })

    df_stats = pd.DataFrame(stats)
    df_stats = df_stats.groupby(
        ["nhomLop", "maDoiTuong", "loaiDoiTuong"]
    ).size().reset_index(name="SoLuong")

    stats_file = os.path.join(out_dir, "ThÃªm thá»‘ng kÃª.xlsx")
    df_stats.to_excel(stats_file, index=False)

    print(f"â¡ ÄÃ£ táº¡o file thá»‘ng kÃª: {stats_file}")

    print("\nğŸ‰ HOÃ€N Táº¤T!")


if __name__ == "__main__":
    main()
