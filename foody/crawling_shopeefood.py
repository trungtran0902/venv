from playwright.sync_api import sync_playwright
import pandas as pd
import time
import os

START_URL = "https://shopeefood.vn/ho-chi-minh/danh-sach-dia-diem-giao-tan-noi"
OUTPUT_FILE = "shopeefood_restaurants.csv"


def auto_save(row):
    df = pd.DataFrame([row])
    if not os.path.exists(OUTPUT_FILE):
        df.to_csv(OUTPUT_FILE, index=False, encoding="utf-8-sig")
    else:
        df.to_csv(OUTPUT_FILE, mode="a", index=False, header=False, encoding="utf-8-sig")


def kill_all_popups(page):
    try:
        page.evaluate("""
        () => {
            const selectors = [
                '.modal',
                '.modal-backdrop',
                '.ReactModal__Overlay',
                '.ReactModal__Content',
                '[role="dialog"]'
            ];
            selectors.forEach(sel => {
                document.querySelectorAll(sel).forEach(el => el.remove());
            });
            document.body.style.overflow = 'auto';
            document.body.style.pointerEvents = 'auto';
        }
        """)
        time.sleep(0.3)
    except:
        pass


def get_shop_links(page):
    links = set()
    anchors = page.query_selector_all('a[href^="/ho-chi-minh/"]')

    for a in anchors:
        href = a.get_attribute("href")
        if not href:
            continue

        # lo·∫°i link category
        if href in ["/ho-chi-minh/fmcg", "/ho-chi-minh/flowers", "/ho-chi-minh/liquor", "/ho-chi-minh/medicine", "/ho-chi-minh/fresh", "/ho-chi-minh/pets"]:
            continue

        if "danh-sach" in href:
            continue

        # shop th·∫≠t th∆∞·ªùng c√≥ slug d√†i
        if href.count("-") < 2:
            continue

        links.add("https://shopeefood.vn" + href)

    return list(links)


def crawl_single_shop(page, url):
    print("üåê M·ªü shop:", url)
    try:
        page.goto(url, timeout=60000)
        page.wait_for_load_state("domcontentloaded")
        time.sleep(1.5)

        kill_all_popups(page)

        name = None
        name_el = page.query_selector("h1")
        if name_el:
            name = name_el.inner_text().strip()

        address = None
        addr_el = page.query_selector("div.address-restaurant")
        if addr_el:
            address = addr_el.inner_text().strip()

        # gi·ªù m·ªü/ƒë√≥ng: ƒë·ªÉ d·∫°ng ‚Äúbest effort‚Äù (n·∫øu trang c√≥ hi·ªÉn th·ªã)
        opening_hours = None
        hours_el = page.query_selector("div.time, span.time, div.operating-time")
        if hours_el:
            opening_hours = hours_el.inner_text().strip()

        row = {"Name": name, "Address": address, "OpeningHours": opening_hours, "URL": url}
        auto_save(row)
        print(f"üíæ Saved: {name} | {address}")

    except Exception as e:
        print("‚ùå L·ªói shop:", e)
        auto_save({"Name": None, "Address": None, "OpeningHours": None, "URL": url})

def scroll_to_bottom(page):
    page.evaluate("""
    async () => {
        for (let i = 0; i < 6; i++) {
            window.scrollBy(0, document.body.scrollHeight);
            await new Promise(r => setTimeout(r, 600));
        }
    }
    """)
    time.sleep(1)

def go_to_next_page_spa(page):
    """
    Pagination ShopeeFood ki·ªÉu SPA + icon.
    Click b·∫±ng JS v√†o ph·∫ßn t·ª≠ cha c·ªßa span.icon-paging-next.
    Sau ƒë√≥ verify ƒë√£ ƒë·ªïi trang b·∫±ng c√°ch so s√°nh shop links.
    """
    kill_all_popups(page)

    # 1) scroll xu·ªëng cu·ªëi ƒë·ªÉ pagination render/enable
    try:
        page.evaluate("() => window.scrollTo(0, document.body.scrollHeight)")
        time.sleep(1.2)
    except:
        pass

    before = set(get_shop_links(page))

    # 2) th·ª≠ click next nhi·ªÅu l·∫ßn theo c√°c c√°ch kh√°c nhau
    clicked = False

    # C√°ch A: click b·∫±ng JS (·ªïn ƒë·ªãnh nh·∫•t)
    try:
        clicked = page.evaluate("""
        () => {
            const icon = document.querySelector('span.icon.icon-paging-next, span.icon-paging-next, span[class*="icon-paging-next"]');
            if (!icon) return false;
            const btn = icon.closest('a,button');
            if (!btn) return false;

            // n·∫øu c√≥ tr·∫°ng th√°i disabled th√¨ b·ªè qua
            const cls = (btn.getAttribute('class') || '').toLowerCase();
            const ariaDisabled = (btn.getAttribute('aria-disabled') || '').toLowerCase();
            if (cls.includes('disabled') || ariaDisabled === 'true') return false;

            btn.click();
            return true;
        }
        """)
    except:
        clicked = False

    # C√°ch B: fallback selector n·∫øu JS kh√¥ng t√¨m th·∫•y
    if not clicked:
        try:
            el = page.query_selector("a:has(span.icon-paging-next), button:has(span.icon-paging-next)")
            if el:
                el.scroll_into_view_if_needed()
                time.sleep(0.5)
                el.click()
                clicked = True
        except:
            clicked = False

    if not clicked:
        print("‚õî Kh√¥ng click ƒë∆∞·ª£c n√∫t Next (icon kh√¥ng th·∫•y/disabled)")
        return False

    # 3) verify ƒë√£ ƒë·ªïi trang: ƒë·ª£i links kh√°c
    try:
        for _ in range(30):  # ~15s
            time.sleep(0.5)
            kill_all_popups(page)
            after = set(get_shop_links(page))
            if after and after != before:
                print("‚û°Ô∏è Sang trang ti·∫øp theo (SPA OK)")
                return True
        print("‚õî Click r·ªìi nh∆∞ng danh s√°ch shop kh√¥ng ƒë·ªïi (c√≥ th·ªÉ Next b·ªã disabled)")
        return False
    except Exception as e:
        print("‚õî L·ªói khi verify trang:", e)
        return False


def main():
    with sync_playwright() as p:
        browser = p.chromium.launch(headless=False)
        page = browser.new_page(viewport={"width": 1280, "height": 800})
        page.on("dialog", lambda d: d.accept())

        crawled = set()
        page_index = 1

        print("üåê M·ªü danh s√°ch ƒë·ªãa ƒëi·ªÉm giao t·∫≠n n∆°i (H·ªì Ch√≠ Minh)...")
        page.goto(START_URL, timeout=60000)
        page.wait_for_load_state("domcontentloaded")
        time.sleep(4)

        while True:
            print(f"\nüìÑ TRANG {page_index}")

            kill_all_popups(page)

            # scroll ƒë·ªÉ load ƒë·ªß shop c·ªßa trang hi·ªán t·∫°i
            for _ in range(4):
                page.mouse.wheel(0, 2500)
                time.sleep(1)

            shop_links = get_shop_links(page)
            print(f"üîó T√¨m th·∫•y {len(shop_links)} shop")

            if not shop_links:
                print("‚õî Kh√¥ng c√≤n shop, d·ª´ng")
                break

            # ===== CRAWL SHOP TRONG TRANG HI·ªÜN T·∫†I =====
            for idx, url in enumerate(shop_links, start=1):
                if url in crawled:
                    continue
                crawled.add(url)

                print(f"üîé ({idx}/{len(shop_links)}) {url}")
                crawl_single_shop(page, url)
                time.sleep(1.2)

                # üîë QUAY L·∫†I LIST PAGE B·∫∞NG HISTORY
                page.go_back()
                page.wait_for_load_state("domcontentloaded")
                time.sleep(1.5)

            # ===== SANG TRANG TI·∫æP THEO (SPA) =====
            print("‚û°Ô∏è Chu·∫©n b·ªã sang trang ti·∫øp theo...")
            scroll_to_bottom(page)

            if not go_to_next_page_spa(page):
                print("‚õî Kh√¥ng c√≤n trang ti·∫øp theo")
                break

            page_index += 1
            time.sleep(3)

        browser.close()

    print("\nüéâ DONE ‚Äì Crawl ho√†n t·∫•t")



if __name__ == "__main__":
    main()
